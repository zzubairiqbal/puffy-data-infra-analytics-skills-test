# Puffy : Data Infrastructure & Marketing Analytics Pipeline

This repository contains my submission for Puffy’s Phase 2 Skills Test (Head of Data Infrastructure & Analytics). It includes:
- an **incoming data quality gate** for raw event exports,
- a **transformation layer** that sessionizes events and computes **7‑day first‑click and last‑click attribution**,
- an **executive summary** based on the transformed tables, and
- a **production monitoring** layer designed to catch the same classes of issues early.

The project is structured the way I would ship a small production pipeline: clear folders, runnable scripts, and validation/reconciliation outputs.

## Quick start (local)

### Prerequisites
- Python 3.9+ (3.10/3.11 recommended)

### Run end-to-end (raw → cleaned → transformed → analysis → monitoring)
1) Place the provided daily CSV exports into `data/raw/` (e.g., `events_20250223.csv` … `events_20250308.csv`).

2) Run Part 1 (DQ checks + cleaned exports):
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .\.venv\Scripts\Activate.ps1

pip install -r part1-data-quality/requirements.txt
python part1-data-quality/run_checks.py --input-dir data/raw --output-dir part1-data-quality/reports
python part1-data-quality/export_cleaned.py --input-dir data/raw --clean-dir data/cleaned --quarantine-dir data/quarantine
```

3) Run Part 2 (sessionization + attribution on cleaned data):
```bash
pip install -r part2-transformation/code/requirements.txt
python part2-transformation/code/pipeline.py --clean-dir data/cleaned --output-dir part2-transformation/output
```

4) Generate Part 3 (executive summary PDF):
```bash
pip install -r part3-analysis/code/requirements.txt
python part3-analysis/code/analyze.py --input-dir part2-transformation/output --output-dir part3-analysis
```

5) Run Part 4 (monitoring):
```bash
pip install -r part4-monitoring/code/requirements.txt
python part4-monitoring/code/monitor.py   --part2-output-dir part2-transformation/output   --dq-results-json part1-data-quality/reports/results.json   --output-dir part4-monitoring/output
```

## Repo structure
- `part1-data-quality/`  
  Incoming data quality checks, severity gating, reports, and an optional cleaner that exports `data/cleaned/` + `data/quarantine/`.
- `part2-transformation/`  
  Sessionization, 7‑day attribution (first/last), and analytics-ready CSV outputs with reconciliation checks.
- `part3-analysis/`  
  `executive-summary.pdf` plus supporting charts/tables generated from Part 2 outputs.
- `part4-monitoring/`  
  Daily monitoring checks (DQ + business KPIs) and alert outputs.
- `data/`  
  Local working directories (`raw/`, `cleaned/`, `quarantine/`). Raw input files are not required to be committed to Git.

## Key outputs (for review)
- Part 1: `part1-data-quality/reports/report.md`, `results.json`, `dq_score.csv`
- Part 2: `part2-transformation/output/sessions.csv`, `purchases.csv`, `purchase_attribution.csv`, `fact_marketing_performance_daily.csv`, `validation/reconciliation.json`
- Part 3: `part3-analysis/executive-summary.pdf`
- Part 4: `part4-monitoring/output/monitoring_report.md`, `alerts.json`

## Notes
- The pipeline is designed so Part 2 runs on **cleaned events** (generated by Part 1) to avoid schema/identity/revenue integrity issues leaking into attribution.
- Where the dataset contains ambiguous or corrupt purchase identifiers, rows are quarantined rather than “fixed” blindly; the quarantine outputs include reasons for auditability.
